{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Imapcts\n",
    "The code in this notebook is used to demonstrate the performance impacts produced by training a model using Differentially Private gradient optimization techniques \n",
    "using PyTorch and Opacus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This cell changes display settings for the notebook.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import neccesary python modules\n",
    "from opacus.utils import module_modification\n",
    "from opacus.dp_model_inspector import DPModelInspector\n",
    "from opacus import PrivacyEngine\n",
    "from random import randint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This cell contains some helper functions used to help train and visualize model training.\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "#     writer.close()\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "#         ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "#             classes[preds[idx]],\n",
    "#             probs[idx] * 100.0,\n",
    "#             classes[labels[idx]]),\n",
    "#                     color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def get_data_set(train,dataset):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    # datasets\n",
    "    if dataset == 'mnist':\n",
    "        return torchvision.datasets.MNIST('./data',\n",
    "            download=True,\n",
    "            train=train,\n",
    "            transform=transform)\n",
    "    else:\n",
    "        print(f\"ERROR LOADING DATASET FOR: {dataset}\")\n",
    "    \n",
    "def get_class_constants(dataset):\n",
    "    if dataset == 'mnist':\n",
    "        return ('zero', 'one', 'two', 'three', 'four','five', 'six', 'seven', 'eight', 'nine')\n",
    "    elif dataset == 'cifar':\n",
    "        return ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') \n",
    "    else:\n",
    "        print(f\"ERROR LOADING CLASS CONSTANTS FOR: {dataset}\")        \n",
    "\n",
    "def get_model_object(num_classes,dp):\n",
    "#     if modeltype == 'alexnet':\n",
    "    return torchvision.models.alexnet(num_classes)\n",
    "#     elif modeltype == 'resnet':\n",
    "#         net = torchvision.models.resnet18(num_classes)\n",
    "#         if dp:\n",
    "#             return module_modification.convert_batchnorm_modules(net)\n",
    "#         return net\n",
    "        \n",
    "def setup_tensorboard_for_experiment(exp_name):\n",
    "    # writer = SummaryWriter('runs/reg_mnist_experiment_1')\n",
    "    writer = SummaryWriter('runs/' + exp_name)\n",
    "    # get some random training images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    images = images.to(device_name)\n",
    "    labels = labels.to(device_name)\n",
    "\n",
    "    # create grid of images\n",
    "    img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    # show images\n",
    "    matplotlib_imshow(img_grid.cpu(), one_channel=True)\n",
    "\n",
    "    # write to tensorboard\n",
    "    writer.add_image('four_mnist_images', img_grid)\n",
    "\n",
    "    # add graph?\n",
    "    # writer.add_graph(net, images)\n",
    "    writer.close()\n",
    "\n",
    "    # select random images and their target indices\n",
    "    images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "    # get the class labels for each image\n",
    "    class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "    # log embeddings\n",
    "    features = images.view(-1, 28 * 28)\n",
    "    writer.add_embedding(features,\n",
    "                        metadata=class_labels,\n",
    "                        label_img=images.unsqueeze(1))\n",
    "#     writer.close()\n",
    "    return writer\n",
    "\n",
    "def save_model(exp_name):\n",
    "#     print(str('./trained_models/'+exp_name+'.pth'))\n",
    "    torch.save(net.state_dict(), str('./trained_models/'+exp_name+'.pth'))\n",
    "    \n",
    "def train_model(exp_name,num_epochs,device_name,writer):\n",
    "    DELTA = 1e-3\n",
    "\n",
    "    running_loss = 0.0\n",
    "    losses = []\n",
    "    top1_acc=[]\n",
    "    virtual_batch_rate = 4\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            images, target = data\n",
    "            images = images.to(device_name)\n",
    "            target = target.to(device_name)\n",
    "\n",
    "            output = net(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "            running_loss += loss.item() \n",
    "            loss.backward()\n",
    "            if dp:\n",
    "                if ((i + 1) % virtual_batch_rate == 0) or ((i + 1) == len(trainloader)):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                else:\n",
    "                    optimizer.virtual_step() # take a virtual step\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            if i % 200 == 199:\n",
    "                # If you will be training over a large number of epochs/dataset\n",
    "                # it may be helpful to save the progress of training periodically.\n",
    "                # Do that by uncommenting the line below:\n",
    "#                 save_model(exp_name) # uncomment to save progress during training\n",
    "                if dp:\n",
    "                    epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(DELTA)\n",
    "                    print(\n",
    "                        f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                        f\"Loss: {np.mean(losses):.6f} \"\n",
    "                        f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                        f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                        f\"Loss: {np.mean(losses):.6f} \"\n",
    "                        f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    )\n",
    "                    \n",
    "                # Here we output Training metrics to TensorBoard so we can see \n",
    "                # how the loss is changing..\n",
    "                writer.add_scalar('training loss',running_loss/200,epoch * len(trainloader) + i)\n",
    "\n",
    "                # Pass tensorboard a set of predicted images, to demonstrate class accuracy during training\n",
    "                writer.add_figure('predictions vs. actuals',plot_classes_preds(net, images, labels),global_step=epoch * len(trainloader) + i)\n",
    "                running_loss = 0.0\n",
    "    writer.close()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#     net,\n",
    "#     batch_size=16,\n",
    "#     sample_size=len(trainset),\n",
    "#     alphas=range(2,32),\n",
    "#     noise_multiplier=.34,\n",
    "#     max_grad_norm=1.2\n",
    "\n",
    "# This cell contains variable names that are relevant in the training of the model\n",
    "# -experiment_name: Name given to the saved model, and also how it will be named in TensorBoard\n",
    "# -experiment_n: Tracks the current experiment we are running - note change this or will overwrite trained models\n",
    "# -dataset: Name of the preloaded PyTorch dataset to experiment with\n",
    "# -dp: Should the model be trained using DP?\n",
    "# -device_name: 'cpu' or 'cuda', specifies torch device\n",
    "# -LR: learning rate for the model\n",
    "experiment_name = ''\n",
    "experiment_n= 0\n",
    "dataset     = 'mnist'  # not being used currently\n",
    "dp          = True\n",
    "device_name = 'cuda'\n",
    "LR = .001\n",
    "\n",
    "if experiment_name =='':\n",
    "    if dp:\n",
    "        experiment_name = f'{dataset}_{experiment_n}_dp'+ '_' +str(randint(100, 999))\n",
    "    else:\n",
    "        experiment_name = f'{dataset}_{experiment_n}'+ '_' +str(randint(100, 999))\n",
    "\n",
    "# DP Engine parameters\n",
    "BATCH_SIZE=64\n",
    "NOISE_MULT = 1.5\n",
    "MAX_GRAD_NORM = 1.2\n",
    "m = .9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This cell is used to load models for display in TensorBoard\n",
    "\n",
    "# Get training and testing dataset\n",
    "trainset=get_data_set(True,dataset)\n",
    "testset=get_data_set(False,dataset)\n",
    "\n",
    "# Get training and testing dataloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = get_class_constants(dataset)\n",
    "\n",
    "# get the model\n",
    "net = get_model_object(len(classes),dp).to(device_name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=m)\n",
    "if dp:\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        net,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sample_size=len(trainset),\n",
    "        alphas=range(2,32),\n",
    "        noise_multiplier=NOISE_MULT,\n",
    "        max_grad_norm=MAX_GRAD_NORM\n",
    "    )   \n",
    "    privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get a writer object so we can write information to tensorboard\n",
    "print(experiment_name)\n",
    "writer = setup_tensorboard_for_experiment(experiment_name)\n",
    "train_model(experiment_name,1,device_name,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a writer object so we can write information to tensorboard\n",
    "dp = False\n",
    "experiment_name += 'nodp'\n",
    "print(experiment_name)\n",
    "writer = setup_tensorboard_for_experiment(experiment_name)\n",
    "train_model(experiment_name,1,device_name,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
