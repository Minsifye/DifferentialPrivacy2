{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Imapcts\n",
    "The code in this notebook is used to demonstrate the performance impacts produced by training a model using Differentially Private gradient optimization techniques \n",
    "using PyTorch and Opacus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell changes display settings for the notebook.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import neccesary python modules\n",
    "from opacus.utils import module_modification\n",
    "from opacus.dp_model_inspector import DPModelInspector\n",
    "from opacus import PrivacyEngine\n",
    "from random import randint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell contains some helper functions used to help train and visualize model training.\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "#     writer.close()\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[idx],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "            color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def get_data_set(train,dataset):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    # datasets\n",
    "    if dataset == 'mnist':\n",
    "        return torchvision.datasets.MNIST('./data',\n",
    "            download=True,\n",
    "            train=train,\n",
    "            transform=transform)\n",
    "    else:\n",
    "        print(f\"ERROR LOADING DATASET FOR: {dataset}\")\n",
    "    \n",
    "def get_class_constants(dataset):\n",
    "    if dataset == 'mnist':\n",
    "        return ('zero', 'one', 'two', 'three', 'four','five', 'six', 'seven', 'eight', 'nine')\n",
    "    elif dataset == 'cifar':\n",
    "        return ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') \n",
    "    else:\n",
    "        print(f\"ERROR LOADING CLASS CONSTANTS FOR: {dataset}\")        \n",
    "\n",
    "def get_model_object(n):\n",
    "#     if modeltype == 'alexnet':\n",
    "    print(f'num classes: {n}')\n",
    "    return torchvision.models.alexnet(num_classes=n)\n",
    "\n",
    "        \n",
    "def setup_tensorboard_for_experiment(exp_name):\n",
    "    # writer = SummaryWriter('runs/reg_mnist_experiment_1')\n",
    "    writer = SummaryWriter('runs/' + exp_name)\n",
    "    # get some random training images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    images = images.to(device_name)\n",
    "    labels = labels.to(device_name)\n",
    "\n",
    "    # create grid of images\n",
    "    img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    # show images\n",
    "    matplotlib_imshow(img_grid.cpu(), one_channel=True)\n",
    "\n",
    "    # write to tensorboard\n",
    "    writer.add_image('four_mnist_images', img_grid)\n",
    "\n",
    "    # add graph?\n",
    "    # writer.add_graph(net, images)\n",
    "    writer.close()\n",
    "\n",
    "    # select random images and their target indices\n",
    "    images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "    # get the class labels for each image\n",
    "    class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "    # log embeddings\n",
    "    features = images.view(-1, 28 * 28)\n",
    "    writer.add_embedding(features,\n",
    "                        metadata=class_labels,\n",
    "                        label_img=images.unsqueeze(1))\n",
    "#     writer.close()\n",
    "    return writer\n",
    "\n",
    "def save_model(exp_name):\n",
    "#     print(str('./trained_models/'+exp_name+'.pth'))\n",
    "    torch.save(net.state_dict(), str('./trained_models/'+exp_name+'.pth'))\n",
    "    \n",
    "def train_model(exp_name,num_epochs,device_name,writer):\n",
    "    DELTA = 1e-3\n",
    "\n",
    "    running_loss = 0.0\n",
    "    losses = []\n",
    "    top1_acc=[]\n",
    "    virtual_batch_rate = VIRTUAL_BATCH_SIZE/BATCH_SIZE\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            images, target = data\n",
    "            images = images.to(device_name)\n",
    "            target = target.to(device_name)\n",
    "\n",
    "            output = net(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "            running_loss += loss.item() \n",
    "            loss.backward()\n",
    "            if dp:\n",
    "                if ((i + 1) % virtual_batch_rate == 0) or ((i + 1) == len(trainloader)):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                else:\n",
    "                    optimizer.virtual_step() # take a virtual step\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            if i % 200 == 199:\n",
    "                # If you will be training over a large number of epochs/dataset\n",
    "                # it may be helpful to save the progress of training periodically.\n",
    "                # Do that by uncommenting the line below:\n",
    "#                 save_model(exp_name) # uncomment to save progress during training\n",
    "                if dp:\n",
    "                    epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(DELTA)\n",
    "                    print(\n",
    "                        f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                        f\"Loss: {np.mean(losses):.6f} \"\n",
    "                        f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                        f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                        f\"Loss: {np.mean(losses):.6f} \"\n",
    "                        f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    )\n",
    "                    \n",
    "                # Here we output Training metrics to TensorBoard so we can see \n",
    "                # how the loss is changing..\n",
    "                writer.add_scalar('training loss',running_loss/200,epoch * len(trainloader) + i)\n",
    "\n",
    "                # Pass tensorboard a set of predicted images, to demonstrate class accuracy during training\n",
    "                writer.add_figure('predictions vs. actuals',plot_classes_preds(net, images, labels),global_step=epoch * len(trainloader) + i)\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    save_model(exp_name) \n",
    "    writer.close()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell contains variable names that are relevant in the training of the model\n",
    " - `experiment_name`: Name given to the saved model, and also how it will be named in TensorBoard\n",
    " - `experiment_n`: Tracks the current experiment we are running - note change this or will overwrite trained models\n",
    " \n",
    " - `dataset`: Name of the preloaded PyTorch dataset to experiment with\n",
    " - `dp`: Should the model be trained differentially private?\n",
    " - `device_name`: 'cpu' or 'cuda', specifies torch device\n",
    " - `LR`: learning rate for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_name = ''\n",
    "experiment_n= 0\n",
    "dataset     = 'mnist'  # not being used currently\n",
    "dp          = True\n",
    "device_name = 'cuda'\n",
    "\n",
    "BATCH_SIZE=8\n",
    "VIRTUAL_BATCH_SIZE=128\n",
    "LR = 9e-4\n",
    "m = .9\n",
    "\n",
    "# DP Engine parameters\n",
    "NOISE_MULT = 1.5\n",
    "MAX_GRAD_NORM = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes: 10\n"
     ]
    }
   ],
   "source": [
    "# This cell is used to load models for display in TensorBoard\n",
    "\n",
    "# Get training and testing dataset\n",
    "trainset=get_data_set(True,dataset)\n",
    "testset=get_data_set(False,dataset)\n",
    "\n",
    "# Get training and testing dataloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = get_class_constants(dataset)\n",
    "\n",
    "# get the model\n",
    "net = get_model_object(len(classes)).to(device_name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=m)\n",
    "# if dp:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impacts on performance\n",
    "There are a few key items that seems to have the most notable impact on performance. First, memory required to load a single training batch into memory during training. \n",
    "Image resolution and batch size play an important role in the amount of memory required to train the network. Similarly, learning rates and number of training epochs impacts the \n",
    "overall performance of the network after training. The differentially private model on average tended to require up to twice as many training epochs to converge to the same \n",
    "value using the same training data and network structure, just adding differentialy privacy to the network's optimizer. Running the code below demonstrates the different rates \n",
    "at which the losses of the differentially private models converge relative to one another. Likewise, learning rates can be adjusted such to demonstrate how learning rates \n",
    "impact training in both differentially private and vanilla models.\n",
    "\n",
    "More specific to the differentially private models, `NOISE_MULT` and `MAX_GRAD_NORM` are parameters that are relevant while training differentially private models. The optimizer \n",
    "uses these parameters to determine how exactly it should apply convolutions and transformations that are part of performing differentially private gradient optimization. From our \n",
    "experiments it seems that a higher `NOISE_MULT`, (and furthermore higher level of noise applied during DP gradient optimization) tended to perform better than models using smaller \n",
    "values.\n",
    "\n",
    "When the cells below are executing, make sure you have tensorboard running using: `tensorboard --logdirs=runs` (make sure you are in the project root directory. You will then be able \n",
    "to visualize more aspects of training the network at `http://localhost:6006`\n",
    "when selecting which execution to examine, look for the name printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_0_dp_941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krizzly/school/5152/project/torchenv2/lib/python3.7/site-packages/opacus/privacy_engine.py:113: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Epoch: 0 \tLoss: 2.303055 Acc@1: 9.500000 (ε = 0.26, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302689 Acc@1: 9.875000 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302533 Acc@1: 10.145833 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302504 Acc@1: 10.125000 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302522 Acc@1: 9.962500 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302480 Acc@1: 9.906250 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302486 Acc@1: 9.812500 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302497 Acc@1: 10.023438 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302515 Acc@1: 10.222222 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302429 Acc@1: 10.550000 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302380 Acc@1: 10.687500 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302355 Acc@1: 10.692708 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302331 Acc@1: 10.730769 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302281 Acc@1: 10.816964 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302282 Acc@1: 10.791667 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302243 Acc@1: 10.828125 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302213 Acc@1: 10.867647 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302203 Acc@1: 10.840278 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302175 Acc@1: 10.888158 (ε = 0.27, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302129 Acc@1: 10.928125 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302095 Acc@1: 10.991071 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302086 Acc@1: 10.982955 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302054 Acc@1: 10.983696 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.302034 Acc@1: 11.000000 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301991 Acc@1: 11.015000 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301962 Acc@1: 11.028846 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301933 Acc@1: 11.050926 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301949 Acc@1: 11.020089 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301942 Acc@1: 11.012931 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301925 Acc@1: 11.035417 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301894 Acc@1: 11.046371 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301858 Acc@1: 11.039062 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301842 Acc@1: 11.053030 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301832 Acc@1: 11.036765 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301826 Acc@1: 11.016071 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301826 Acc@1: 11.008681 (ε = 0.28, δ = 0.001)\n",
      "\tTrain Epoch: 0 \tLoss: 2.301838 Acc@1: 10.979730 (ε = 0.28, δ = 0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krizzly/school/5152/project/torchenv2/lib/python3.7/site-packages/opacus/privacy_engine.py:273: UserWarning: PrivacyEngine expected a batch of size 128 but the last step received a batch of size 96. This means that the privacy analysis will be a bit more pessimistic. You can set `drop_last = True` in your PyTorch dataloader to avoid this problem completely\n",
      "  f\"PrivacyEngine expected a batch of size {self.batch_size} \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABNCAYAAACoqK8xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxD0lEQVR4nO29aWxcV5ag+d0IxsJ9D+77pl0Uqc1aLCullOU1y860y+nKysyeLlQNkA10o6cwnT0FDBKoP90z6AG6MYPuysEkprLQZaczRyovsizJkmXZ2kmLIimS4ibuZJAMLkFGBIOxvPnBuDeDWkmZEUG53gcQJB8jgufd9+55557tCk3T0NHR0dH57mKItQA6Ojo6OpFFV/Q6Ojo633F0Ra+jo6PzHUdX9Do6OjrfcXRFr6Ojo/MdR1f0Ojo6Ot9xIqLohRDHhRB3hRDdQohfRuJ/6Ojo6OisDLHWefRCCCPQCXwfGAJuAj/WNK1tTf+Rjo6Ojs6KiIRFvxvo1jStV9O0ReB94AcR+D86Ojo6OisgEoq+ABgM+30odExHR0dHJwbExeofCyH+EvhLgISEhPqNGzfGSpQVEQwGATAY1nf8OhAIYDAYEELEWpTH4vf7iYuL2e23YnQ51w5N0wgGgxiNxliL8lielbnu9/u5ffv2pKZp2U96bSTujGGgKOz3wtCxZWia9mvg1wC1tbVaQ0NDBERZO9xuNwAJCQkxluTxzM7OkpCQgMlkirUoj2VycpKMjIx1P5nGx8ex2WyxFuOxaJqGw+EgKysr1qI8Fp/Ph9vtJjU1NdaiPJZnZa5PTExgs9n6V/LaSMyym0CVEKJMCGEG3gE+isD/0dHR0dFZAWtu0Wua5hdC/CvgDGAEfqNp2p21/j86Ojo6OisjIk49TdM+BT6NxGfrRA9N0whPv5V+//Xu/9d5MsFgcNn1lXGd9X5tpczBYPCBc4Cle9NgMGA0GtfN+WiaRiAQUPEzo9EYdZfl+o7e6MSMQCDA4uIiPp+PQCCAEAKTyaS+1sME0lkZ9yvDYDCIy+ViamqK+fl5TCYTaWlpZGRkLAvorscHu9/vx+12Mzw8THt7O52dnfj9fmBJTovFwq5du9iyZQspKSkxv1c1TWN+fp6+vj6uXbvGpk2b2Lx5M8nJyVENSn9nFH0gEMDlcjE7O4vH40HTNEwmE1arlYSEBIxGI0ajEYvFsi6i/oFAQEX3JdIaiWWAMhgM4vV6cTqdTExMMDExwezsLEajEZvNhs1mIyMjg4SEBOLi4taVEngUPp8Pj8fD9PQ0FouF1NRULBbLug8Ef1uCwSALCws4nU5mZmaUQvT7/QwODtLV1cXExARms5mysjK2bt2KxWIBwGg0kpiYSGpq6rq51pqm4fF46Ozs5MyZM1y4cIEbN27g8/nUisRqtfLyyy/z9ttvs2vXLjIyMtQ5xYJgMMjY2BgfffQR77//Pm+88QZ5eXkkJibqin6lhC/j3G43ly5d4vTp0zQ2NuL3+yksLKS6upr6+npsNhtpaWlUVVWRkJAQtUkebk2Fy+vxeHC5XOp1QgjMZjPx8fGYzWa19IwmUjF0d3dz/fp1mpubaWtrY2RkBJPJxObNm9m4cSO7du1ix44dpKenExcXt67TOYPBIDMzM9y8eZP33nuPTZs28aMf/Yji4uKYKoBII69le3s7p06d4quvvmJyclL93e12s7CwgM/nUwoyOTlZXceEhATq6uo4evQoe/bsIS0tDbPZHPOHo8Ph4OzZs3zyySe0tbXh8XjU34QQ+Hw+PvvsMxwOB36/n/3795OVlRUz407TNHp7e7l8+TKTk5MsLi4ql1M0eWYVfTAYxOfz4XK5GBwc5Pr161y8eJGrV68yNDREMBiku7ub9vZ2WltbSUlJITc3l9dee41t27aRkZER8YuvaRoLCwu43W68Xi+Li4s4nU617BwZGVGvlRZUQUEBO3bsYPPmzVFXRC6Xi9u3b3Pq1CkaGhro7+9nfHyc+fl5DAYDk5OTaky7u7vZsWMHBQUF5OXlYbVaoyrrSpAP1JaWFt5//31u3LhBRUUFVqs15gor0rhcLi5fvsynn37KlStX6OnpYXFx8ZHn7XQ6sdvt+Hw+/H4/RqORkZERxsfH6enp4fnnn6eiooLU1NSYjp3L5aK/v5+hoaEHDCVYmnMzMzM0NDSQkZGB1Wpl//79JCUlxUTZa5rG2NgYnZ2dLC4ukpiYSHx8fNQNo2dS0csJPDo6SmdnJ1988QXnz5/n3r17uFwuhBAYjUZcLhfd3d309vZiMBjIysrC6XTi9/vZs2cPSUlJa1JkEm6py4ni8/mYm5vDbrczODjI7Owss7OzjI2NcffuXW7fvo3dbldPdqno8/PzOXz4MD//+c8pKSmJ2rI5GAwyNTXFqVOn+OSTT+ju7iYQCCj5AoEAExMTOBwOurq6uHfvHs3NzWzdupV9+/ZRUlJCcnLyurD6JMFgkLm5Oa5fv86lS5coLCykpqaG9PT0iE56eT/I+8Dr9SrrGVCBuXAMBgPx8fFYrVZMJhMWi+Vb+ZcXFha4efMm3d3dxMXFsWfPHlJTUx/7QA4EAjgcDgYGBhgdHWVkZIQzZ85w9+5dJiYmeOONN9i2bRsWiyVmKziLxUJ2djYFBQV4PB5l0ZvNZkwmEwaDAa/Xy/z8POfPnyc/P5/S0lLKy8ujruiDwSCLi4s4HA5mZmYIBoPqGuvB2Ccgfcjd3d38/ve/5/Lly9y9exen04nP58NqtSr/l8vlwul0Kn/45OQkp0+fVg+CPXv2kJiY+NSDLqPpUrl7vV5lBXV3d3Pt2jXu3bvH7OwsXq932eu8Xu8DLg+3201PTw9TU1P09/fz53/+5xw8eJC0tLSI3qRyTKXlMT4+rvy595+vdJO1tbUxMDDA5cuX+fjjj/ne977HD3/4Q4qKirBarVFTBFKpPizDIhAIMD8/j8PhwGKxcPDgQbZt2xbRiSbviYWFBRwOB4ODgzQ3N9PR0YHdbkcIwczMDNPT08tiNAkJCWzbto3NmzdTVVVFTU0NWVlZT61UrVYr+/bto6CggISEBMrKyrDZbCQlJT3yPX6/n6GhIS5dusS5c+dobGxkZmaGnp4ezpw5Q3p6OsXFxWRmZsakIE8IQW5uLm+99RZWq5UbN27Q3d1NMBgkKyuLvLw8TCYTfX19dHZ24nK56O3tpa2tjcLCwqg/oPx+P1NTU4yNjbGwsBDTOMczpeilJX/hwgU+/vhjrl27Rl9fHy6XC6PRSGZmJocOHeLAgQOkpqZy8eJF3nvvPRYWFoClgZ+YmODixYskJCSQm5tLeXn5Uy2lNE1jbm6O3t5eWlpaGB0dxel0Mj4+rr63t7ezsLCA1WolJSWF+Ph4UlNTqaysJCUlZZkfXj75b968yeDgIFeuXFETX742EgQCATweD3fv3uXUqVO0tLQwPz//xHP3eDwsLCwwPT3N0NAQ8/PzeL1e3nrrLcrKyqK2PF1YWMDj8ZCUlITZbF72t0AgwODgIGNjY2RkZPDiiy9SXFwcsbGUrjq73c5XX31Fa2srw8PDDA4OMjAwwOzsLEIINXbyPdLw6O/vp7W1lby8PHbs2MH3vvc95cJb7VhaLBa2bdvGhg0bMJlMJCQkqFXCowgGg6SkpJCRkUF+fj5Wq5WLFy8qhdnQ0KBWcLGqbo2Pj6eiooJ33nmHF154gZmZGTRNW+YSuXv3Ll9++SVnz57l1q1b2Gw2KisrVXwumkaIx+PB7XargHGseCYUvVwGLyws0NfXxz/8wz/w8ccf4/f7lVVkMpkoLi7mhRde4O233yYhIYGCggKGh4fp6OjA4XDgdrvRNI3+/n7Onz/Phg0biI+Pp6Cg4KlcDg6HgzNnzvDxxx/T0dHBwsICBoNB3XTJyclUV1dTWlpKXl6eUvS1tbWkpaUtm3QLCwsMDg4qn57H48FutzM1NUVxcfGajqdEBux6e3v58MMP+eSTTxgZGWFxcXHZ61JSUsjJyVEKR9M0FhcXmZmZweFw4PF4aG5uxul0kpyczCuvvEJJSUnEMlvCreahoSHsdjs7duxYpugDgYBy2wwODlJYWEhFRQVJSUkRmejyHh0fH+fzzz/nt7/9LS0tLbhcrofme0ukLPKhNDQ0hNlspqWlBbfbTV5eHtnZ2au2oM1m8wMtEZ503gaDAavVSn5+Pnv37uXGjRtcv36d+fl55ubmaG9v58aNG2zfvj1mij4uLo6kpCQqKiqoqKh4IIde0zRlvN2+fZuOjg4uXbpEVVUV6enpFBUVRVXRSzddtIOv9/NMKHqZOdHe3s7p06e5ffv2A8pIKvqysjISExMxmUzU19fzq1/9ihMnTnDu3DlaW1vVpBsdHeXjjz9GCMHx48fJz89fteUkrXCn00kwGMRqtZKWlsbWrVspLy8nNTWVHTt2sGnTJpXTazAYHpqpEgwGKSwspLm5mStXrqiUuOnp6YjcJFJZDw4O8rvf/Y6zZ8/S3d2txlXmzRuNRurr63nttddISUlBCEEgEGB2dpampiZOnTql3GbDw8OcOHECv9/PG2+8ETE3jt/vZ25ujra2Ns6fP8/09DTl5eWkpKSoc/N4PNy7d4/Lly8zNTVFfX19RF1KwWCQ+fl5rl69yh/+8Afu3LmD0+lc5laSKb7yd/kQlC4x+X1xcZHe3l6ampro6ekhOTn5qVwlTzrX+7PBNE3D6/UyNzfH+Pg409PTeL3ehxbNxZLHFUJpmkZSUhJlZWXk5OTQ1dWlVli7du2isLAwytKuD54JRe/3+2lpaeHEiRNcuXIFu93+wGuMRiNJSUkqum4wGEhKSmLjxo289NJLjI2N0dHRoRSZy+Xi1q1byuf8k5/8hKysrFUFZ7Oysnj11VepqalREfXExERsNhvp6elYLBYyMjLURH3cJAkEAmpVIQN1sgZgLZEKxefz0dHRwYcffsjnn39OT0+PCmwZDAZyc3PZs2cP5eXl7N69m7q6OpUFJBVCRUUFQgi+/PJLRkZG8Hg8dHR0YLVa0TSNN998c02VvbSaR0ZGuHz5Mvfu3cNsNnPw4EGSk5OXvVZa+6Ojo2RnZ7Np06aIZjH5/X5GR0f55ptvaGpqUkpeBtltNhulpaXk5+eTkZFBeno6WVlZmEwm5ufnGR4exuVyYbfbaWhoYHJykpmZGebm5h4I3H5bpKXp9/vx+/1MT08rg+XevXsqq+XmzZvLgp0ymB0fH7+m8qw18kEgrenFxUXGx8dVs7J/jjwTij4QCNDQ0MD58+fp6+t7wJq3WCzYbDbKysrIzMxUSsVoNJKQkEBVVRWVlZUkJiYqd4/MMJA+yO3bt1NfX6/Sx56kmIQQpKamsmvXLurq6jAajcuUefj3lSg5qcQWFxeXKfq1DCCFW2xjY2P84Q9/4OTJk/T39+P1ejGZTCQmJpKSksJzzz3HG2+8QW1tLTk5OcTHxz9ggSYlJWEwGPB4PHz55ZdMTU0xNzdHY2MjTqeThIQEXn31VUpKStbELy6zaK5du8aJEyfIz8/n5ZdfZu/evcuCjJqm4XK5GBoaAqCyspLt27dHNIDo8/no7Oykp6dHrcKkr7umpoby8nKqq6upqqpShkBqaipGo5GFhQXGxsZUjGZsbAyn07nM6l8rpJKfnJxU/6e1tZXu7m7sdjvt7e0MDg4yPz+Pz+cjGAyqPPvU1FTS0tJUNtF6KKJ6GHLFJ1eaMhPH4/HErI23XNHFqubkmVD04dkt91s3QghycnI4ePAgr7/+OiUlJcsmh8FgIDk5mbKyMqqqqrhz547Kv5Wf29nZyW9+8xsAlYmzEsUU3rPi2/bVkK4SWTDl9XpxuVwqrrAWyCq9c+fO8emnn9LU1KSKOAwGAxkZGdTX11NdXc2hQ4fYt2+fcoOFj6lUQOnp6ezdu5fBwUGmpqa4evUqXq8Xt9vN3bt3+bu/+ztSU1MpKipaE0Xv8/lobm5WbqZ9+/ZRXV390Os1OzvLwMAAVquVDRs2UFFRETFFL1eFt27dorOzE1iKaxw+fJjvf//77Nmzh5ycHJUqK1040o1jMBgoLCwkPj6evr4+gGWxnrVU9tKtdfbsWU6ePMnQ0BBTU1N4PB4WFxfxeDx4vd5lGUFCCOLi4rDb7Vy6dImEhARqampITU1dlwVzbrebgYEBXC6XMkpmZmYYHx/H4/GosY8mRqNRZQTG4gH5TCj6x2EymaipqeHgwYMUFxc/4CaQAabnnnsOp9PJBx98oAKHEqfTyVdffUVaWprqlbGS5elaNk1aXFxkeHiY4eFh3G43BoOBzMxM0tPT12SiyxTK/v5+rl27xuXLl5mZmQGWAlz5+fkcOnSIV155hcrKSvLz85XF+Sji4uJITk6mrq6Ojo4OWltblRXo8Xjo6+tjfHx8zR5UcmXX2NjI4uIiW7duxWazLZs40i01MTHB4OAgZrOZvLw81QZjrZGKs7+/n7a2NuUqeumll3jllVeor69XaZKPu47hD7GZmRkOHDjA0aNHKS8vX1OXkzRuxsfHaWlpYXBwUOX3P+kcOzs7cbvdjIyMsHnzZurr66msrCQzM3NdFaHJFbs0CuPj49m6dSv5+fkxkzEuLo6MjAyysrIwm826ol8NcXFxqpJ0165dD02dkq0FSkpK+JM/+ROVV9/c3KysZZktcfHiRWw2G9u3b4+qH1IG8r766iva2tpYXFwkNzeXjRs3UlBQsGZuD7fbTXt7O+3t7Xi9XuLi4khJSaG0tJRdu3Zx7Ngxnn/++VVZHUajkeLiYmpqakhLS2Nubg6v1/ut5X0YgUCAoaEhBgcHSU9Px+l04nQ61YpECIHf72dyclLlWGdnZ5OcnBxRK0oW5nV1deHxeNi8eTNvv/02O3fuJCUl5YkWr8/nY2RkhJMnT3Ly5EkyMjI4cOAAr7zyCjk5OQ+kjX5bjEYjlZWV7N69G03TmJ2dxe/3q7iWrC2Zn5/H5XKp2g+73c74+DhNTU3k5eWxZ88eXnjhBV544QVKS0vXRf8gaWRMTEyo+zA5OZktW7ZQUlISs4I+k8lEeno6GRkZMWm09kwr+uTkZF566SVee+01iouLHzkh5NIzMzOTH//4x5jNZtxuN52dnSrYJHOgZUO0aBIMBnE4HHz11Ve0t7eTkpLCvn37qKurW7OSc5kpIxWSz+cjKSmJAwcO8O6777Jp0yZVULOaPjtGo5GMjAyqq6tJS0tjeHhpM7FIjKFcQQkhsNvt/O3f/i07duygurpaZTXJvjaNjY14PB7Ky8tJTEyM6MSSxoKMW5SWllJVVbWiDoWapuF2u2lsbKS3t5dAIEB2djb19fXk5+evubtJVuAePnyYvLw8PvroI3p6epidncVqtbJp0yYqKipISEigtbWV3t5eJiYm6OnpYWJigoWFBRV4/vzzz2lubmZoaIif/vSnKvC+Vor0cSmpD7ueMl24oaGBkydPMj4+DixZ9Hl5eaSlpa3buEKkeaYVvcViUZkMT7ImZAvT3NxcDh8+zMjICHa7fVlTpEfdWJFEBkgnJibo6+tjbm6OyspK6urqyM3NXbOnv8vl4sMPP+Ty5cvKbWWxWMjPz2fnzp3YbDaVTvk0xWOy+vhhTdzWCqPRyM6dO+nu7ubKlSvKVdLS0qJWIS6Xi46ODpxOJ0VFRWzbto2CgoKoTW7ZIdVqtT4xgysQCOB2u+nu7ubrr79WrTri4+NJTEyMSCWnNHqSk5NVu1yHw6FWeDk5Ocr3Xltbq7Jx7t69S1tbG7dv36a7u5vZ2Vmmp6eZmZnh1KlTGAwGfvCDH1BdXb2sOdpqkT51mRU0MzOjAsNxcXGkpqYql2K4r12uWJuamjh37pwqVpTZQnV1dWvmBn0aZGtot9sdk4DwM6now/vDpKSkrHhCSDdOeXk5x44d4/r168tyhWNR1BAMBlVam9PpxGQyUVRUxPbt27/VhLmfmZkZ/umf/onGxkaCwaBqh5yQkEBaWtpTp0AGAgFmZmbo7e1VbjGZVpiamkpiYuKayA9Ly9/nnnuOhYUFUlJSVDWy1+tV/3dubk51ZExPT+fgwYPk5eVFdFLJOJDBYFD7os7NzZGZmflA/ED6jmVmSG9vL+fOnePy5ctMTExETRHJYG9NTY2SDZZby5mZmVRVVREIBNizZw9dXV1cvHiRxsZGbt++zejoKB6Ph9bWVpxOp6qqfdoWvLJXVHgNSWtrKwMDA3g8HuLj46mqqmLjxo0kJyeTmJio7ltZx/Hee+9x4cIFtTLPzs5m48aNqr4mVta8z+djdnYWh8MRk4ylZ0bRh+8oE35stUg/5IYNG6ivr2d4eJiBgYFlRSPRQgZIBwYGaGpqYnZ2FpvNRnV1tbKw1/p/yXQ5me0R7g55Gvx+P+3t7dy8eVP1yBFCkJiYyO7du1Wu/VogYzI/+tGPOHbsGC6Xi5GREXp7e0lPT8fr9dLe3s4//uM/0tfXR1JSkur1EslJJRttxcfH43a76erq4urVq8THx2Oz2ZTy9vv9zM/PMzMzw8DAAF988QXNzc20tLQwPj7OwsKCarQXLYW/EoVsMBhISUlRhYAvvvgi58+f58MPP1SJDS6XS3U6fdo5tLi4qAoZr127xvDwMJOTk3g8HmWcJCUlkZWVRW5uLjk5OWRmZqq+VkNDQ3z99deqzsZqtbJ3716+//3vx1TJwx9dpzMzM6onVzR5ZhT9w7Y6k9bw4uLiqm4uWUadlpa2TAmsZRbNSgjvF37lyhVcLhc7duxg+/btqy7eehIPy+9fCzRNY3JyUi3/wytBTSbTmlou0v1msVhISUkhEAiQn5/Phg0bMJvNeDwe0tPTOXfuHC6Xa8V+8rWQSfZN6u7upr+/nw8//JDe3l7KysrUA9vj8aixGhkZ4datWypnXWKz2di/fz/Z2dkRk1lWRQcCAYxGo0r5fNw5xsXFERcXh9VqJSkpSVWXDw4O4nQ6VbHc8PAwGzduXLU8fr+fsbExTp48yenTp7l16xazs7MPndcyZTrcjeN2u5U7aXFxkbS0NI4ePcrrr7++rNgvVsj08PA6mWjyzCh6eFBJ+Xw+lQdcUFCwqs+6f69M+bmRUvT3+x4DgQBjY2OcPn2as2fP0tzcjNVqVTv9yODiWiEVksFgWJNVi3RDSEtubm5u2efKBnKyQnStCfc1y2Ipl8tFcnIyFouFvLw8KioqojLBTSYTWVlZVFRUkJ2dTVdXF5988gkXLlxY5hKT7Q3Ct2gMX5UajUaqq6s5fvw4WVlZEe/JMzExQXJyMpmZmSQmJq4o7U+6qXJyclSbD1gyWlpbW+nv71/19ZYut4aGBj744AM6OjpUDvzDkAae0+lURXHyc+R7MjMzOXbsGIcOHSInJ2dd7CoXS54JRS/dDPcvZ91uN1euXKGuro5Nmzat2AIOBoOqCtXv9ysr1Gw2R6QfSnhTNofDQV9fH319fQwNDakArBCClJQUqqqq1iylMhyj0Uhubi5JSUnMzc0tky18gqy0ijcQCDA9Pa16vbe1tS3Lx5aTUXZpjBTy4SyVRWtrK9PT08rii8YENxgMmM1mioqKyMvLo6enR/ma5bWFB8f6/vPIyMigpKREtdSNBDJoeerUKc6dO6eqoA8dOqTSD1di8MgEAtlWQFbPPk0qqN/vp7W1ldOnT9PT0/NYJS+5fxzvl1eusmSq6HrJtIlVLPCZUfQ5OTkUFhYyNDSklj4+n4/BwUG14ciTlqDwxx1oWlpa6OrqYmpqCkBlGezatWvNU9p8Pp8qULl69arauUn669xuN1VVVRw5coR9+/ZFpC2xrNS02+1cu3ZNFRbJNsNyNx5ZCfuoibG4uIjb7cbpdNLU1MSJEydUUDv8Bk5KSlKVq9GYZJqm4XA4VGCwsLCQrKysqPm6zWYze/bsYWhoiPHxcXp7ex+ZqivL4c1ms9qjID4+nkOHDnHkyBGVBhgJ5F4O165d4/z581itVkZHRxkYGGDv3r2qCO1RBo90+4yNjdHW1sb09DSwpFg3bNjwVN0hg8EgIyMjDA8Pr1l688LCAv39/WzduvWBPkixQho/8/PzUTNCJM+EojcYDFRWVlJRUUFDQ4MqhJDFEbKQ41HVj+HZDouLi7S2tvL73/+eK1eu4HA4sFqtVFZWcujQIerr69c8COrxeLhx4wbvv/8+586dU/tGBgIB4uLiyM7OZufOnfz4xz+msrLygSwiqZSDwaBKKVutAktISODYsWP09PTQ1tbG/Pw8CwsL3Lt3jzNnzpCZmamaViUnJz/y82dnZ+nt7aWjo4PLly9z6tQp5ubmlrkgZNqrrLKNxpaNgUAAu93OnTt3WFhYwGazUVJSEjGFeT9ms5nKykpeeeUVFhcXaWhoYGRkRO0sFQwGMZlMJCUlKWtdNjGbm5sjOTmZAwcOsH///oh22fT5fPT19WG325mfn1eFerdv3+bixYu8/fbbHDt2jIKCgmUporIBms/nY3JykqtXr3L9+nVmZ2cBVEZMbm7uUz1cZaxgNecdFxeH2WzGbDarB5CcW06nk4aGBjZs2KBicbF238h41uTkpEqdjhbPhKI3Go0UFRVRUVGB2Wxe1qvG7XYzNjZGX1+f2iwhHJmyJbf16+rq4syZM5w9e1ZZI9XV1fz1X/81Bw8eJCMjY02Vg8/nU5kEly9fVlkJ4a6SzMxMKioqVMFJ+N+lm2lkZIT5+XlVRr3aqL3cmEU2b7t+/brKOx4ZGVFpp3V1dWRnZz+wBJeKfGRkhDt37nDv3j0GBwcfUPIGg4GioiL27t1LWVlZVLILZI5yZ2cnvb29xMfHU1NTE9H+NvcjfdebN2+msLCQ6elp7HY7fX19TExMsLi4SHp6ukqbHRkZ4cSJE1y4cIGFhQUyMjJUz/RIKiRpeUuFLF2Kss+Nz+ejt7eXI0eOsGPHDhUrmJycZHBwkM7OTm7cuMG1a9cYHx8nEAgghCA+Pp6ioiLS0tJWLZMQgqysLLVzVXhty/2vk19Go5H09HRVR+Pz+RgYGODevXvMzc0xOzvL559/TlxcHJqmsXv37phk3oS7weQD6FFB5kjyRI0mhCgCfgvkABrwa03T/rMQIgP4HVAK9AFva5o2LZbO6j8DLwNu4Oeapn3zbYQ0GAykpaWpTTxkBSssRbN7enq4ceMGGzZsUFaIEEL5I+/du8etW7dobm5mcHCQpqYm7HY7cXFxFBUVcfDgQfbt26dSGtcyI0X6jW/fvs3ExIRSiuGKfHp6mq6uLpqamsjNzcVisSgfuMPhwOFwqKrJbdu2ceTIkVUX00hFVFVVRXV1tdoUY2ZmRvW8kRtfpKSkLHvYhd+U09PTDAwMqGwnSVxcHPHx8eTk5HD06FHeeOMNtbVbpCdXeFdOTdOora2ltrZWFf5Ei/BGZNnZ2RQXF7Nx40ZVJGO1WlU6YEJCgkp5lc3hCgsLIz5eRqMRm83Ghg0bKC0tpb+/XwWG5b3qcDjU6qi0tBSj0UhPTw+9vb0MDQ1x584dxsfH8Xq9CCEoLS3l+PHj7N2796mKkoxGIxUVFTz//POMjo5y69YttXMU/NH/n52djc1mIzc3l6KiIoqKiigsLCQ7Oxu/309XVxenT5+moaGBmZkZRkZG+OKLL4iLi8NisbBlyxa1p0I0kMVv8fHxmEwmVQE/Njb2VKnh34aVzAI/8D9pmvaNECIZaBRCnAN+DpzXNO0/CCF+CfwS+HfAS0BV6GsP8F9D358aeaGlxTk+Pr6s1H5oaIhr166xZcsWhBBqgksl/9FHH3HhwgXa29tVxoPVaqWmpoZ9+/Zx/PhxMjMz17zZUDAYZHx8nMbGRiYnJ5elVcl4gvRPnjlzhunpafLy8lQ75e7ubtra2pQFUFZWhsFg4Lnnnlu1LAaDAZPJRF5eHlu2bKGpqUlZwgsLC2iahtPppLm5+YFgnFxhyKCnLE6SKZRms5nMzEyqq6vZuHEjr776KnV1dTFZLicmJrJlyxZKS0tj0lMEUIkDcXFxJCYmPhDo9nq9TE9P09PTg9PpZMuWLRw5coScnJyIyyYfMnv37mV0dJSrV68yOjrK/Py86lzZ19enlKTcnm9ubk5Z/OFWfHp6OseOHeMnP/kJGzZseKqaBaPRSH5+PkePHsXtdpOSkkJbW5vy1ycmJlJQUEBNTQ0lJSWUl5ezbds2tfKU91hdXZ3KKrtx4wbz8/P09/fz6aefIoTgpz/9Kdu3b49aUzGZBmqz2UhNTWVmZga73c7o6Oj6U/Sapo0Co6Gf54QQ7UAB8APghdDL/h64yJKi/wHwW23p7r4mhEgTQuSFPuepkAolNzeX/fv309zcrBQ9wNzcHDdu3GBqaoqdO3eybds20tPTaW9v5+uvv6anpweHw6FcPtK98O6773L06FFKSkrWfI9T6VcfHx+nr69PrUBkBpG8+LOzs6oS8MqVK1itVvUAkJMPICcnh927d/P6668/deqdwWBQFrfL5eL27du0t7dz9+7dZQ3eHnYu4fnx8rMSExPJzs6mvLyc/fv38+KLL5Kbm6t8orEoN5dFNdHeCPphPCx7JRgMMjU1xa1btxgeHsZkMqmWF9GwNqXRVFdXR3FxMW+++SbXr1/n1q1b3Lp1Syl9r9eLw+FQ5yBTQeX9m5aWRk1NDYcPH+bll19my5YtT33NpSsmNzeXP/3TP2Xv3r309vZit9vx+/2UlJSwYcMGUlJSVGaP3P82PKMmIyODH/7whyQlJREMBmlsbGR2dha73c5nn31GRUUFxcXFa16j8ijkQ3Xz5s3U1dVx5coVJicnsdvt60/RhyOEKAV2ANeBnDDlPcaSaweWHgKDYW8bCh1bpuiFEH8J/CWwou29ZHXe9u3byc3NXfY3uUuODIC1t7eTlpZGV1cX7e3tatPjqqoqampqKCgoYOPGjSroFImNrKVylDnzUlHKtK/jx49TUVFBX18fo6OjKuVSxg1gyTotKytjy5YtVFdXs3//fuWeehrkJM/Pz+fVV1+ltraWpqYmbt68SUdHByMjI0xPTz/xJpR+3o0bN1JSUsKWLVuora2N6D6xK0W21PX5fDFJY3sSMq4k9wGwWCxkZmaqFWWkkUo1KSlJuZgKCwupr6+nvb2dtrY2WlpaaGtrw+l0LnvwS1m3bt3K5s2b2bFjB7W1tRQWFqo0xm8jl8ViISsrSzWGc7vdau7KLJXHzVOTyYTNZuPw4cMsLCxgNBr55ptvmJqaYmxsTPW2ipaSlQZqQUEB5eXlNDY2LtsAJZqsWNELIZKA/w/4N5qmOe9b2mtCiFXNKk3Tfg38GqC2tnZF75VNuMrKysjNzWV2dnbZJgmyWm9iYkJZIUIIkpOT2bRpE/v27ePQoUOqU6PFYnmqJl4rQVpC0urNycnBarVis9nYtWsX7777LtXV1Wrbtrt376pqQPn+zMxMNm/ezJEjRyguLiY1NXVN2qxaLBbKysooKiqipqaGTZs2ceXKFe7cuUNnZ+cDbYbvz1dOT0/npZdeYv/+/RQWFqo2A7HMV5aWptfrZXBwkLGxsTXvprhWyAA7oDaRj/YDUhacJSYmqtz93bt309/fz5dffsmlS5fo7+9Xq2BAJQ0cPXqU3bt3k5ubq+7HtZJd+rWtVisZGRlK1pV+vnQDvf7666oK9caNG1G3oCXSlVxYWIjZbGZubk61wUhKSorKwx1WqOiFECaWlPx/1zTtROiwXbpkhBB5wHjo+DBQFPb2wtCxb430ef3Zn/0ZKSkpfPbZZ3R2di6rypTVh9JCSE9PZ+vWrbz88su8+OKL2Gw2FRyJZCWsnEhZWVls376dlJQUta3h1q1bKSoqIj4+Xh177rnneOutt9STXr4/Pj5e3RBPk1b5ONmMRiNZWVns3buXyspK7HY7DofjodaG7DUCf0ylk5soyK6XsUKej8Viwev18sUXX5Cenq7cC9HuK/I4NE1jfn6eqakpAoGA6tcSq4eRtPBlemN5eTk5OTkcO3bsgXJ9eT/KJniR6u3+beelbEn+5ptvEhcXh9frpaenJ2YtipOTkykpKSExMRGHw0FzczMffPAB77zzDiUlJVGRaSVZNwL4f4B2TdP+j7A/fQT8DPgPoe8fhh3/V0KI91kKws5+G//8fbJgNpupqanBbDaTlpbGN998Q0NDAz09PeqmNJvNFBQUsHXrVmpqatTGJAUFBVHd3UVmOBw6dIjdu3erTpEpKSlqksj0P1lKHk3keMotDHNych7qo3/Y+8IflrFGuqRKSkooLS2lvb1dbRsXK0vuYQQCATweD11dXXR2drK4uEh5eXlUag1WQrg1nZmZ+chir/Dv6xF5X+fk5HD8+HEyMjIYGRlh586dpKWlRXWshRAkJSVRX1/PL37xCyYmJkhKSqKqqiqqBshKLPr9wJ8DLUKIptCx/4UlBf+BEOJfAv3A26G/fcpSamU3S+mV/2ItBTYajSQmJlJdXU12dja1tbXk5+dz8eJFVY6dnp5OfX09Bw4coLa2ltzcXLWEj+YNKt1GslVveB7wepoo0pdoMplW7NdeT+dgMBiwWCzU1NSoytLKykpsNtu6UKASn8/HvXv3uHr1Ks3NzcTFxVFdXU11dfW6kvNZUOZPQt7T0i2laRoGg2HNVsWrkUP2sPqLv/iLZT22ornCWEnWzdfAo6Q58pDXa8AvvqVcj0X2FsnMzGTnzp1UV1fzs5/9TFlv0veYnJwc0SXmSmVdbz7ih/GsT26j0UhJSQl/9Vd/xfz8PElJSaSnp0e1+vBxyNYb7733Hp9//jmBQIDt27ezb98+CgoKoprv/8+JWGwEfj/h7rFY8czeXVLZm81mkpOTV929Uue7hyxOWW/ITJv+/n46Ozux2+1kZGSo2Eh8fPwzYQzoPLs8s4peR+dZQVZIj4+Pk5uby44dO1SBkM1me2ZXUTrPDrqi19GJMEII0tLS2L9/P1u2bFF7mcpdqXRFrxNp1oWilxWk6xkZ6E1ISIixJI9ndnaWhISEdeObfhQOhwO/37/uXRYTExNr+nkJCQnqHlpYWFiTfv2yX9J6yjB6GLIl9/11GuuNZ2WuT05Orvi1Yj1UDwoh5oC7sZbjCWQBKx/Z6LPe5QNdxrVivcu43uWD746MJZqmPXHfyXVh0QN3NU3bGWshHocQomE9y7je5QNdxrVivcu43uWDf34yru91s46Ojo7Ot0ZX9Do6OjrfcdaLov91rAVYAetdxvUuH+gyrhXrXcb1Lh/8M5NxXQRjdXR0dHQix3qx6HV0dHR0IkTMFb0Q4rgQ4q4Qoju0JWEsZCgSQnwhhGgTQtwRQvzr0PFfCSGGhRBNoa+Xw97z70My3xVCvBglOfuEEC0hWRpCxzKEEOeEEF2h7+mh40II8V9CMjYLIeoiLFtN2Dg1CSGcQoh/E+sxFEL8RggxLoRoDTu26jETQvws9PouIcTPoiDj/y6E6AjJcVIIkRY6XiqE8ISN538Le0996P7oDp3HmlViPULGVV/bSM33R8j3uzDZ+kSoKWMMx/BReiby96PcCSkWX4AR6AHKATNwG9gUAznygLrQz8lAJ7AJ+BXw1w95/aaQrBagLHQOxijI2Qdk3XfsfwN+Gfr5l8B/DP38MnCapYZ0e4HrUb6uY0BJrMcQeB6oA1qfdsyADKA39D099HN6hGU8BsSFfv6PYTKWhr/uvs+5EZJbhM7jpQjLuKprG8n5/jD57vv7fwL+1xiP4aP0TMTvx1hb9LuBbk3TejVNWwTeZ2nP2aiiadqopmnfhH6eA+S+uI/iB8D7mqZ5NU27x1JL5t2Rl/SRsvx96Oe/B/4k7PhvtSWuAWliaYOYaHAE6NE0rf8xr4nKGGqadgmYesj/Xs2YvQic0zRtStO0aeAccDySMmqadlbTNLk5wDWWNvB5JCE5UzRNu6YtaYPfhp1XRGR8DI+6thGb74+TL2SVvw2897jPiMIYPkrPRPx+jLWif9T+sjFDLN8XF5Y2UWkOLQ3TQ8diJbcGnBVCNIqlPXdh9Xv3RoN3WD6p1tMYwurHLNb36f/AkmUnKRNC3BJCfCmEOBg6VhCSSxItGVdzbWM1jgcBu6ZpXWHHYjqG4tvtv73qcYy1ol9XiPv2xQX+K1AB1LK0ufl/ip10ABzQNK0OeAn4hRDi+fA/hqyQmKZRCSHMwOvA70OH1tsYLmM9jNnjEEL8DeAH/nvo0ChQrGnaDuDfAv8ohEiJkXjr+tqG8WOWGx4xHcOH6BlFpO7HWCv6iO0vu1rEQ/bF1TTNrmlaQNO0IPB/80fXQkzk1jRtOPR9HDgZkscuXTIiSnv3PoGXgG80TbOHZF1XYxhitWMWE1mFED8HXgX+LKQACLlDHKGfG1nyeVeH5Al370Rcxqe4tlEfRyFEHPAm8LswuWM2hg/TM0Thfoy1or8JVAkhykKW4Dss7TkbVUI+vAf2xb3Pp/0GICP6HwHvCCEsQogyoIqlIE4kZUwUQiTLn1kK1rXyx7174cG9e38aitzvZQ337n0Cy6yn9TSGYax2zM4Ax4QQ6SH3xLHQsYghhDgO/M/A65qmucOOZwshjKGfy1kat96QnE4hxN7Q/fzTsPOKlIyrvbaxmO9HgQ5N05RLJlZj+Cg9QzTux7WKKD/tF0uR5U6Wnqp/EyMZDrC0XGoGmkJfLwP/ALSEjn8E5IW9529CMt9lDSPzj5GxnKUshdvAHTlWQCZwHugCPgcyQscF8H+FZGwBdkZBxkTAAaSGHYvpGLL00BkFfCz5Mv/l04wZS37y7tDXv4iCjN0s+WHl/fjfQq/9Yej6NwHfAK+Ffc5OlpRtD/B/EiqIjKCMq762kZrvD5MvdPz/Bf7H+14bqzF8lJ6J+P2oV8bq6OjofMeJtetGR0dHRyfC6IpeR0dH5zuOruh1dHR0vuPoil5HR0fnO46u6HV0dHS+4+iKXkdHR+c7jq7odXR0dL7j6IpeR0dH5zvO/w97COe0HzqluAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine(\n",
    "    net,\n",
    "    batch_size=VIRTUAL_BATCH_SIZE,\n",
    "    sample_size=len(trainset),\n",
    "    alphas=range(2,32),\n",
    "    noise_multiplier=NOISE_MULT,\n",
    "    max_grad_norm=MAX_GRAD_NORM\n",
    ")   \n",
    "privacy_engine.attach(optimizer)\n",
    "LR = 9e-5\n",
    "experiment_name = f'{dataset}_{experiment_n}_dp'+ '_' +str(randint(100, 999))\n",
    "print(experiment_name)\n",
    "writer = setup_tensorboard_for_experiment(experiment_name)\n",
    "train_model(experiment_name,1,device_name,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_0_191\n",
      "\tTrain Epoch: 0 \tLoss: 2.301841 Acc@1: 10.500000 \n",
      "\tTrain Epoch: 0 \tLoss: 2.301406 Acc@1: 11.250000 \n",
      "\tTrain Epoch: 0 \tLoss: 2.301264 Acc@1: 11.354167 \n",
      "\tTrain Epoch: 0 \tLoss: 2.301307 Acc@1: 11.140625 \n",
      "\tTrain Epoch: 0 \tLoss: 2.300798 Acc@1: 11.237500 \n",
      "\tTrain Epoch: 0 \tLoss: 2.300165 Acc@1: 11.833333 \n",
      "\tTrain Epoch: 0 \tLoss: 2.297768 Acc@1: 13.026786 \n",
      "\tTrain Epoch: 0 \tLoss: 2.276041 Acc@1: 14.546875 \n",
      "\tTrain Epoch: 0 \tLoss: 2.170456 Acc@1: 19.194444 \n",
      "\tTrain Epoch: 0 \tLoss: 2.022578 Acc@1: 25.000000 \n",
      "\tTrain Epoch: 0 \tLoss: 1.873521 Acc@1: 30.721591 \n",
      "\tTrain Epoch: 0 \tLoss: 1.741766 Acc@1: 35.708333 \n",
      "\tTrain Epoch: 0 \tLoss: 1.624113 Acc@1: 40.139423 \n",
      "\tTrain Epoch: 0 \tLoss: 1.523655 Acc@1: 43.968750 \n",
      "\tTrain Epoch: 0 \tLoss: 1.435149 Acc@1: 47.283333 \n",
      "\tTrain Epoch: 0 \tLoss: 1.357684 Acc@1: 50.171875 \n",
      "\tTrain Epoch: 0 \tLoss: 1.290419 Acc@1: 52.698529 \n",
      "\tTrain Epoch: 0 \tLoss: 1.227934 Acc@1: 55.065972 \n",
      "\tTrain Epoch: 0 \tLoss: 1.172145 Acc@1: 57.151316 \n",
      "\tTrain Epoch: 0 \tLoss: 1.121535 Acc@1: 59.031250 \n"
     ]
    }
   ],
   "source": [
    "# Trains a model WITHOUT differential privacy enabled\n",
    "LR= 9e-5\n",
    "dp = False\n",
    "experiment_name = f'{dataset}_{experiment_n}'+ '_' +str(randint(100, 999))\n",
    "print(experiment_name)\n",
    "writer = setup_tensorboard_for_experiment(experiment_name)\n",
    "train_model(experiment_name,1,device_name,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
